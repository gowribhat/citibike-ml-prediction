{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36f9f228-a6d4-4112-ac74-64a0b564ac85",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# CS4225/CS5425Â Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cd9efa8-6a6f-44eb-b02c-70f21dff0a0e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Introduction\n",
    "1. Citibike data (both training and testing) saves in DBFS with filepath `dbfs:/citibike_data/`\n",
    "2. Weather data (`weather_data_training.csv` and `weather_data_testing.csv`) uploaded to `dbfs:/FileStore/`\n",
    "3. All DataFrames are saved to `dbfs:/dataframes` to ensure data persistence using cloud storage despite cluster timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccfc2f1b-1142-4a36-ae5a-3a1deca6548a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8e43948-c4b8-43f1-9b8f-a15fa2624814",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Step 1:** Download and unzip all training and testing citibike data to local filesystem on driver node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ab35642-5eee-416d-b53e-b74b45995869",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r 27 33.9M   27 9640k    0     0  8547k      0  0:00:04  0:00:01  0:00:03 8546k\r100 33.9M  100 33.9M    0     0  16.4M      0  0:00:02  0:00:02 --:--:-- 16.4M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202201-citibike-tripdata.csv.zip\n  inflating: 202201-citibike-tripdata.csv  \n  inflating: __MACOSX/._202201-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0 41.4M    0  117k    0     0   196k      0  0:03:36 --:--:--  0:03:36  195k\r 45 41.4M   45 19.0M    0     0  12.1M      0  0:00:03  0:00:01  0:00:02 12.1M\r100 41.4M  100 41.4M    0     0  17.1M      0  0:00:02  0:00:02 --:--:-- 17.1M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202202-citibike-tripdata.csv.zip\n  inflating: 202202-citibike-tripdata.csv  \n  inflating: __MACOSX/._202202-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0 63.3M    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r 20 63.3M   20 13.0M    0     0  9496k      0  0:00:06  0:00:01  0:00:05 9490k\r 59 63.3M   59 37.6M    0     0  15.5M      0  0:00:04  0:00:02  0:00:02 15.5M\r 96 63.3M   96 61.2M    0     0  18.1M      0  0:00:03  0:00:03 --:--:-- 18.1M\r100 63.3M  100 63.3M    0     0  18.3M      0  0:00:03  0:00:03 --:--:-- 18.3M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202203-citibike-tripdata.csv.zip\n  inflating: 202203-citibike-tripdata.csv  \n  inflating: __MACOSX/._202203-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  5 76.9M    5 4168k    0     0  3875k      0  0:00:20  0:00:01  0:00:19 3874k\r 37 76.9M   37 29.1M    0     0  14.0M      0  0:00:05  0:00:02  0:00:03 14.0M\r 71 76.9M   71 54.8M    0     0  17.8M      0  0:00:04  0:00:03  0:00:01 17.8M\r100 76.9M  100 76.9M    0     0  19.9M      0  0:00:03  0:00:03 --:--:-- 19.9M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202204-citibike-tripdata.csv.zip\n  inflating: 202204-citibike-tripdata.csv  \n  inflating: __MACOSX/._202204-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0 97.7M    0  287k    0     0   345k      0  0:04:49 --:--:--  0:04:49  345k\r 21 97.7M   21 21.3M    0     0  11.4M      0  0:00:08  0:00:01  0:00:07 11.4M\r 45 97.7M   45 44.3M    0     0  15.6M      0  0:00:06  0:00:02  0:00:04 15.6M\r 70 97.7M   70 69.2M    0     0  17.9M      0  0:00:05  0:00:03  0:00:02 17.9M\r 95 97.7M   95 92.9M    0     0  19.3M      0  0:00:05  0:00:04  0:00:01 19.3M\r100 97.7M  100 97.7M    0     0  19.5M      0  0:00:05  0:00:05 --:--:-- 23.3M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202205-citibike-tripdata.csv.zip\n  inflating: 202205-citibike-tripdata.csv  \n  inflating: __MACOSX/._202205-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0  116M    0  984k    0     0  1185k      0  0:01:40 --:--:--  0:01:40 1184k\r 21  116M   21 25.1M    0     0  13.9M      0  0:00:08  0:00:01  0:00:07 13.9M\r 44  116M   44 51.3M    0     0  18.3M      0  0:00:06  0:00:02  0:00:04 18.3M\r 69  116M   69 80.8M    0     0  21.1M      0  0:00:05  0:00:03  0:00:02 21.1M\r 94  116M   94  110M    0     0  22.9M      0  0:00:05  0:00:04  0:00:01 22.9M\r100  116M  100  116M    0     0  23.2M      0  0:00:05  0:00:05 --:--:-- 27.6M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202206-citbike-tripdata.csv.zip\n  inflating: 202206-citbike-tripdata.csv  \n  inflating: __MACOSX/._202206-citbike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0  111M    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r 11  111M   11 12.2M    0     0  8948k      0  0:00:12  0:00:01  0:00:11 8943k\r 33  111M   33 36.9M    0     0  15.2M      0  0:00:07  0:00:02  0:00:05 15.2M\r 55  111M   55 62.0M    0     0  18.0M      0  0:00:06  0:00:03  0:00:03 18.0M\r 78  111M   78 87.1M    0     0  19.7M      0  0:00:05  0:00:04  0:00:01 19.7M\r100  111M  100  111M    0     0  20.9M      0  0:00:05  0:00:05 --:--:-- 23.3M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202207-citbike-tripdata.csv.zip\n  inflating: 202207-citbike-tripdata.csv  \n  inflating: __MACOSX/._202207-citbike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0  126M    0 18976    0     0  39725      0  0:55:43 --:--:--  0:55:43 39698\r 13  126M   13 16.6M    0     0  11.2M      0  0:00:11  0:00:01  0:00:10 11.2M\r 32  126M   32 41.2M    0     0  16.6M      0  0:00:07  0:00:02  0:00:05 16.6M\r 51  126M   51 64.6M    0     0  18.2M      0  0:00:06  0:00:03  0:00:03 18.2M\r 69  126M   69 87.7M    0     0  19.5M      0  0:00:06  0:00:04  0:00:02 19.5M\r 88  126M   88  112M    0     0  20.4M      0  0:00:06  0:00:05  0:00:01 22.4M\r100  126M  100  126M    0     0  21.0M      0  0:00:06  0:00:06 --:--:-- 24.2M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202208-citibike-tripdata.csv.zip\n  inflating: 202208-citibike-tripdata.csv  \n  inflating: __MACOSX/._202208-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0  118M    0 1103k    0     0  1491k      0  0:01:21 --:--:--  0:01:21 1491k\r 21  118M   21 25.5M    0     0  14.7M      0  0:00:08  0:00:01  0:00:07 14.7M\r 43  118M   43 51.4M    0     0  18.8M      0  0:00:06  0:00:02  0:00:04 18.8M\r 63  118M   63 75.6M    0     0  20.3M      0  0:00:05  0:00:03  0:00:02 20.3M\r 86  118M   86  102M    0     0  21.8M      0  0:00:05  0:00:04  0:00:01 21.8M\r100  118M  100  118M    0     0  22.6M      0  0:00:05  0:00:05 --:--:-- 26.1M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202209-citibike-tripdata.csv.zip\n  inflating: 202209-citibike-tripdata.csv  \n  inflating: __MACOSX/._202209-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0  110M    0  117k    0     0   172k      0  0:10:56 --:--:--  0:10:56  172k\r 17  110M   17 18.9M    0     0  11.3M      0  0:00:09  0:00:01  0:00:08 11.3M\r 39  110M   39 43.1M    0     0  16.2M      0  0:00:06  0:00:02  0:00:04 16.2M\r 61  110M   61 67.6M    0     0  18.5M      0  0:00:05  0:00:03  0:00:02 18.5M\r 83  110M   83 92.6M    0     0  19.9M      0  0:00:05  0:00:04  0:00:01 19.9M\r100  110M  100  110M    0     0  20.6M      0  0:00:05  0:00:05 --:--:-- 23.6M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202210-citibike-tripdata.csv.zip\n  inflating: 202210-citibike-tripdata.csv  \n  inflating: __MACOSX/._202210-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0 92.5M    0  206k    0     0   291k      0  0:05:25 --:--:--  0:05:25  290k\r 17 92.5M   17 16.5M    0     0   9.8M      0  0:00:09  0:00:01  0:00:08  9.8M\r 48 92.5M   48 44.6M    0     0  16.5M      0  0:00:05  0:00:02  0:00:03 16.5M\r 75 92.5M   75 69.6M    0     0  18.8M      0  0:00:04  0:00:03  0:00:01 18.8M\r100 92.5M  100 92.5M    0     0  20.4M      0  0:00:04  0:00:04 --:--:-- 20.4M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202211-citibike-tripdata.csv.zip\n  inflating: 202211-citibike-tripdata.csv  \n  inflating: __MACOSX/._202211-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0 58.3M    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r 15 58.3M   15 9208k    0     0  6926k      0  0:00:08  0:00:01  0:00:07 6923k\r 56 58.3M   56 32.8M    0     0  14.0M      0  0:00:04  0:00:02  0:00:02 14.0M\r 96 58.3M   96 56.0M    0     0  16.8M      0  0:00:03  0:00:03 --:--:-- 16.8M\r100 58.3M  100 58.3M    0     0  17.1M      0  0:00:03  0:00:03 --:--:-- 17.1M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202212-citibike-tripdata.csv.zip\n  inflating: 202212-citibike-tripdata.csv  \n  inflating: __MACOSX/._202212-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0 66.3M    0  490k    0     0   582k      0  0:01:56 --:--:--  0:01:56  581k\r 32 66.3M   32 21.7M    0     0  11.6M      0  0:00:05  0:00:01  0:00:04 11.6M\r 69 66.3M   69 46.1M    0     0  16.0M      0  0:00:04  0:00:02  0:00:02 16.0M\r100 66.3M  100 66.3M    0     0  17.9M      0  0:00:03  0:00:03 --:--:-- 17.9M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202301-citibike-tripdata.csv.zip\n  inflating: 202301-citibike-tripdata.csv  \n  inflating: __MACOSX/._202301-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  1 62.4M    1 1086k    0     0   893k      0  0:01:11  0:00:01  0:01:10  892k\r 39 62.4M   39 24.8M    0     0  11.0M      0  0:00:05  0:00:02  0:00:03 11.0M\r 78 62.4M   78 48.8M    0     0  15.2M      0  0:00:04  0:00:03  0:00:01 15.2M\r100 62.4M  100 62.4M    0     0  16.7M      0  0:00:03  0:00:03 --:--:-- 16.7M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202302-citibike-tripdata.csv.zip\n  inflating: 202302-citibike-tripdata.csv  \n  inflating: __MACOSX/._202302-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  6 81.8M    6 5155k    0     0  4440k      0  0:00:18  0:00:01  0:00:17 4440k\r 38 81.8M   38 31.1M    0     0  14.2M      0  0:00:05  0:00:02  0:00:03 14.2M\r 69 81.8M   69 56.6M    0     0  17.9M      0  0:00:04  0:00:03  0:00:01 17.9M\r100 81.8M  100 81.8M    0     0  20.4M      0  0:00:04  0:00:04 --:--:-- 20.4M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202303-citibike-tripdata.csv.zip\n  inflating: 202303-citibike-tripdata.csv  \n  inflating: __MACOSX/._202303-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  6 99.2M    6 6467k    0     0  6286k      0  0:00:16  0:00:01  0:00:15 6291k\r 32 99.2M   32 32.5M    0     0  16.1M      0  0:00:06  0:00:02  0:00:04 16.1M\r 58 99.2M   58 57.7M    0     0  19.2M      0  0:00:05  0:00:03  0:00:02 19.2M\r 84 99.2M   84 84.0M    0     0  20.9M      0  0:00:04  0:00:04 --:--:-- 20.9M\r100 99.2M  100 99.2M    0     0  21.7M      0  0:00:04  0:00:04 --:--:-- 21.7M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202304-citibike-tripdata.csv.zip\n  inflating: 202304-citibike-tripdata.csv  \n  inflating: __MACOSX/._202304-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  1  130M    1 2326k    0     0  2473k      0  0:00:54 --:--:--  0:00:54 2472k\r 19  130M   19 26.1M    0     0  13.4M      0  0:00:09  0:00:01  0:00:08 13.4M\r 39  130M   39 51.1M    0     0  17.3M      0  0:00:07  0:00:02  0:00:05 17.3M\r 58  130M   58 76.8M    0     0  19.5M      0  0:00:06  0:00:03  0:00:03 19.5M\r 78  130M   78  102M    0     0  20.8M      0  0:00:06  0:00:04  0:00:02 20.8M\r 98  130M   98  129M    0     0  21.7M      0  0:00:06  0:00:05  0:00:01 25.3M\r100  130M  100  130M    0     0  21.8M      0  0:00:05  0:00:05 --:--:-- 25.8M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202305-citibike-tripdata.csv.zip\n  inflating: 202305-citibike-tripdata.csv  \n  inflating: __MACOSX/._202305-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0  135M    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  8  135M    8 11.9M    0     0  8930k      0  0:00:15  0:00:01  0:00:14 8928k\r 26  135M   26 36.2M    0     0  15.3M      0  0:00:08  0:00:02  0:00:06 15.3M\r 44  135M   44 60.5M    0     0  17.9M      0  0:00:07  0:00:03  0:00:04 17.9M\r 63  135M   63 85.7M    0     0  19.6M      0  0:00:06  0:00:04  0:00:02 19.6M\r 82  135M   82  111M    0     0  20.7M      0  0:00:06  0:00:05  0:00:01 22.5M\r100  135M  100  135M    0     0  21.5M      0  0:00:06  0:00:06 --:--:-- 25.1M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202306-citibike-tripdata.csv.zip\n  inflating: 202306-citibike-tripdata.csv  \n  inflating: __MACOSX/._202306-citibike-tripdata.csv  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0  145M    0  882k    0     0  1024k      0  0:02:25 --:--:--  0:02:25 1023k\r 15  145M   15 22.3M    0     0  12.1M      0  0:00:11  0:00:01  0:00:10 12.1M\r 32  145M   32 47.0M    0     0  16.6M      0  0:00:08  0:00:02  0:00:06 16.6M\r 48  145M   48 70.7M    0     0  18.5M      0  0:00:07  0:00:03  0:00:04 18.5M\r 65  145M   65 95.8M    0     0  19.9M      0  0:00:07  0:00:04  0:00:03 19.8M\r 83  145M   83  121M    0     0  20.8M      0  0:00:06  0:00:05  0:00:01 24.3M\r100  145M  100  145M    0     0  21.6M      0  0:00:06  0:00:06 --:--:-- 25.1M\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/202307-citibike-tripdata.csv.zip\n  inflating: 202307-citibike-tripdata.csv  \n  inflating: __MACOSX/._202307-citibike-tripdata.csv  \n\u001B[1mDownloaded and unzipped Citibike data\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "\n",
    "base_url=\"https://s3.amazonaws.com/tripdata/\"\n",
    "ext=\".csv.zip\"\n",
    "years=(\"2022\" \"2023\")\n",
    "\n",
    "for year in \"${years[@]}\"; do\n",
    "  for month in {01..12}; do\n",
    "      if [ \"$year\" == \"2022\" ] && { [ \"$month\" == \"06\" ] || [ \"$month\" == \"07\" ]; }; then\n",
    "        name_suffix=\"-citbike-tripdata\"\n",
    "      elif [ \"$year\" == \"2023\" ] && [ \"$month\" == \"08\" ]; then\n",
    "        break  # Break out of the loop for July in 2023\n",
    "      else\n",
    "        name_suffix=\"-citibike-tripdata\"\n",
    "      fi\n",
    "\n",
    "      file_name=\"${year}${month}${name_suffix}${ext}\"\n",
    "      url=\"${base_url}${file_name}\"\n",
    "      output_path=\"/tmp/${file_name}\"\n",
    "      \n",
    "      curl \"$url\" --output \"$output_path\"\n",
    "      unzip -n \"$output_path\"\n",
    "  done\n",
    "done\n",
    "echo -e \"\\e[1mDownloaded and unzipped Citibike data\\e[0m\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ce1312b-06ae-4ccd-9c2b-de437c1d9c22",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Step 2:** Move all downloaded csv data files from local filesystem on driver node to `citibike_data` folder in DBFS. Skips if file does not exist or has already been moved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "877fcca1-a08e-4957-a6a9-8a95fbb4e7f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 202201-citibike-tripdata.csv\nMoved 202202-citibike-tripdata.csv\nMoved 202203-citibike-tripdata.csv\nMoved 202204-citibike-tripdata.csv\nMoved 202205-citibike-tripdata.csv\nMoved 202206-citibike-tripdata.csv\nMoved 202207-citibike-tripdata.csv\nMoved 202208-citibike-tripdata.csv\nMoved 202209-citibike-tripdata.csv\nMoved 202210-citibike-tripdata.csv\nMoved 202211-citibike-tripdata.csv\nMoved 202212-citibike-tripdata.csv\nMoved 202301-citibike-tripdata.csv\nMoved 202302-citibike-tripdata.csv\nMoved 202303-citibike-tripdata.csv\nMoved 202304-citibike-tripdata.csv\nMoved 202305-citibike-tripdata.csv\nMoved 202306-citibike-tripdata.csv\nMoved 202307-citibike-tripdata.csv\nAll csv files moved into `citibike_data`.\n"
     ]
    }
   ],
   "source": [
    "years = [\"2022\", \"2023\"]\n",
    "csv_ext = \".csv\"\n",
    "correct_suffix = \"-citibike-tripdata\" \n",
    "\n",
    "for year in years:\n",
    "    end_month = 8 if year == \"2023\" else 13\n",
    "    \n",
    "    for month in range(1, end_month):\n",
    "        name_suffix = \"-citbike-tripdata\" if (year == \"2022\" and (month == 6 or month == 7)) else \"-citibike-tripdata\"\n",
    "\n",
    "        file_name = f\"{year}{month:02d}{name_suffix}{csv_ext}\"\n",
    "        final_file_name = f\"{year}{month:02d}{correct_suffix}{csv_ext}\"\n",
    "\n",
    "        try:\n",
    "            local_file_path = f\"file:/databricks/driver/{file_name}\"\n",
    "            dbfs_destination_path = f\"dbfs:/citibike_data/{final_file_name}\"\n",
    "            dbutils.fs.mv(local_file_path, dbfs_destination_path)\n",
    "            print(f\"Moved {final_file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"File {file_name} does not exist. Skipping.\")\n",
    "\n",
    "print(\"All csv files moved into `citibike_data`.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c8b0aed-30c1-4e2d-8ddb-a8841bb03230",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Step 3:** Create and save `citibike_dataframe` using citibike data for both training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2c22b70-2ef6-402b-a4b5-bf8505bfa6ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated data till $202201-citibike-tripdata.csv\nAggregated data till $202202-citibike-tripdata.csv\nAggregated data till $202203-citibike-tripdata.csv\nAggregated data till $202204-citibike-tripdata.csv\nAggregated data till $202205-citibike-tripdata.csv\nAggregated data till $202206-citibike-tripdata.csv\nAggregated data till $202207-citibike-tripdata.csv\nAggregated data till $202208-citibike-tripdata.csv\nAggregated data till $202209-citibike-tripdata.csv\nAggregated data till $202210-citibike-tripdata.csv\nAggregated data till $202211-citibike-tripdata.csv\nAggregated data till $202212-citibike-tripdata.csv\nAggregated data till $202301-citibike-tripdata.csv\nAggregated data till $202302-citibike-tripdata.csv\nAggregated data till $202303-citibike-tripdata.csv\nAggregated data till $202304-citibike-tripdata.csv\nAggregated data till $202305-citibike-tripdata.csv\nAggregated data till $202306-citibike-tripdata.csv\nAggregated data till $202307-citibike-tripdata.csv\n+----------+-----------+-----+----+----------+\n|  datetime|day_of_week|month|year|trip_count|\n+----------+-----------+-----+----+----------+\n|2022-01-01|          7|    1|2022|     20895|\n|2022-01-02|          1|    1|2022|     44234|\n|2022-01-03|          2|    1|2022|     34126|\n|2022-01-04|          3|    1|2022|     37879|\n|2022-01-05|          4|    1|2022|     35080|\n|2022-01-06|          5|    1|2022|     46004|\n|2022-01-07|          6|    1|2022|     17838|\n|2022-01-08|          7|    1|2022|     25129|\n|2022-01-09|          1|    1|2022|     22088|\n|2022-01-10|          2|    1|2022|     35717|\n|2022-01-11|          3|    1|2022|     27704|\n|2022-01-12|          4|    1|2022|     41636|\n|2022-01-13|          5|    1|2022|     51798|\n|2022-01-14|          6|    1|2022|     46837|\n|2022-01-15|          7|    1|2022|     23717|\n|2022-01-16|          1|    1|2022|     21588|\n|2022-01-17|          2|    1|2022|     29887|\n|2022-01-18|          3|    1|2022|     44045|\n|2022-01-19|          4|    1|2022|     55371|\n|2022-01-20|          5|    1|2022|     34901|\n+----------+-----------+-----+----+----------+\nonly showing top 20 rows\n\nCitibike dataframe created and saved in DBFS\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, to_date, dayofweek, month, year\n",
    "from pyspark.sql.types import StructType, StructField, DateType, IntegerType\n",
    "\n",
    "folder_path = \"dbfs:/citibike_data/\"\n",
    "files = dbutils.fs.ls(folder_path)\n",
    "\n",
    "citibike_schema = StructType([\n",
    "    StructField(\"datetime\", DateType(), True),\n",
    "    StructField(\"day_of_week\", IntegerType(), True),\n",
    "    StructField(\"month\", IntegerType(), True),\n",
    "    StructField(\"year\", IntegerType(), True),\n",
    "    StructField(\"trip_count\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "citibike_dataframe = spark.createDataFrame([], schema=citibike_schema)\n",
    "\n",
    "for file in files:\n",
    "    file_name = file.name\n",
    "    file_path = f\"{folder_path}{file_name}\"\n",
    "    file_data = spark.read.format(\"csv\").option(\"header\", \"true\").load(file_path)\n",
    "\n",
    "    df_with_trip_count = (file_data\n",
    "        .withColumn(\"datetime\", to_date(\"started_at\"))\n",
    "        .withColumn(\"day_of_week\", dayofweek(\"datetime\"))\n",
    "        .withColumn(\"month\", month(\"datetime\"))\n",
    "        .withColumn(\"year\", year(\"datetime\"))\n",
    "        .groupBy(\"datetime\", \"day_of_week\", \"month\", \"year\")\n",
    "        .agg(count(\"*\").alias(\"trip_count\"))\n",
    "    )\n",
    "\n",
    "    citibike_dataframe = citibike_dataframe.union(df_with_trip_count)\n",
    "    print(f\"Aggregated data till ${file_name}\")\n",
    "\n",
    "citibike_dataframe = citibike_dataframe.orderBy(\"datetime\")\n",
    "\n",
    "citibike_dataframe.show()\n",
    "citibike_dataframe.write.format('delta').mode('overwrite').save(\"dbfs:/dataframes/citibike_dataframe\")\n",
    "print(\"Citibike dataframe created and saved in DBFS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb0b78f5-bb66-47a4-842d-9988f92de2ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Step 4:** Create and save `weather_dataframe` using weather data for both training and testing. Extract out relevent features.<br>\n",
    "*Ensure `weather_data_training.csv` and `weather_data_testing.csv` are correctly uploaded to `dbfs:/FileStore/`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68e31ab7-c07b-4751-b0f2-6ecabf1668d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated data till $weather_data_training.csv\nAggregated data till $weather_data_testing.csv\n+----------+----+---------+--------+------+----------+---------+---------+----------+----------+--------------+-----------+\n|  datetime|temp|feelslike|humidity|precip|precipprob|snowdepth|windspeed|cloudcover|visibility|solarradiation|solarenergy|\n+----------+----+---------+--------+------+----------+---------+---------+----------+----------+--------------+-----------+\n|2022-01-01|11.6|     11.6|    91.6|18.463|       100|      0.0|     13.1|     100.0|       8.7|          14.7|        1.3|\n|2022-01-02|10.2|      9.4|    83.8| 2.318|       100|      0.0|     22.9|      91.5|      11.8|          26.0|        2.1|\n|2022-01-03|-1.0|     -6.2|    49.9|   0.0|         0|      0.0|     26.1|      63.4|      16.0|          12.5|        1.1|\n|2022-01-04|-2.6|     -6.5|    49.1|   0.0|         0|      0.0|     19.9|      10.1|      16.0|         105.8|        9.1|\n|2022-01-05| 4.2|      2.0|    77.0| 5.745|       100|      0.0|     20.5|      67.2|      13.5|          23.9|        2.1|\n|2022-01-06| 3.2|      0.3|    50.2|   0.0|         0|      2.5|     21.3|      31.2|      16.0|          65.7|        5.8|\n|2022-01-07|-0.9|     -5.9|    65.9| 9.314|       100|     10.4|     24.0|      72.4|      10.1|          78.0|        6.7|\n|2022-01-08|-3.3|     -7.4|    44.1|   0.0|         0|      8.2|     24.0|       7.9|      16.0|         112.9|        9.7|\n|2022-01-09| 2.2|     -1.7|    66.8| 2.765|       100|      5.4|     22.3|      77.8|      14.8|          29.8|        2.5|\n|2022-01-10|-0.7|     -5.6|    47.0|   0.0|         0|      1.7|     33.6|      41.7|      15.9|         103.4|        8.9|\n|2022-01-11|-7.3|    -12.9|    40.8|   0.0|         0|      0.1|     35.3|      10.7|      15.5|         115.1|       10.1|\n|2022-01-12|-0.2|     -3.8|    46.2|   0.0|         0|      0.0|     22.3|      16.5|      16.0|          94.1|        8.3|\n|2022-01-13| 4.4|      3.2|    59.3|   0.0|         0|      0.0|     11.6|      39.4|      15.7|          82.5|        7.1|\n|2022-01-14| 3.1|     -0.7|    66.2|   0.0|         0|      0.0|     29.6|      34.6|      15.9|          89.0|        7.8|\n|2022-01-15|-8.7|    -14.9|    45.3|   0.0|         0|      0.0|     22.4|      14.2|      16.0|          98.6|        8.7|\n|2022-01-16|-6.3|    -11.9|    64.9| 5.546|       100|      0.1|     29.3|      57.0|      13.6|          64.7|        5.6|\n|2022-01-17| 3.6|     -0.7|    75.8|26.429|       100|      0.4|     34.9|      98.7|      12.4|          17.9|        1.6|\n|2022-01-18| 0.6|     -4.2|    46.6|   0.0|         0|      0.0|     28.8|      52.4|      16.0|          99.9|        8.7|\n|2022-01-19| 4.6|      2.1|    47.9|   0.0|         0|      0.0|     22.3|      29.0|      16.0|          74.8|        6.4|\n|2022-01-20| 2.1|     -1.5|    61.3| 6.116|       100|      0.3|     22.3|      69.8|      12.6|          37.3|        3.1|\n+----------+----+---------+--------+------+----------+---------+---------+----------+----------+--------------+-----------+\nonly showing top 20 rows\n\nWeather dataframe created and saved in DBFS\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, to_date, dayofweek, month, year, lit, when\n",
    "from pyspark.sql.types import StructType, StructField, DateType, IntegerType, FloatType\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "folder_path = \"dbfs:/FileStore/\"\n",
    "files = [\"weather_data_training.csv\", \"weather_data_testing.csv\"]\n",
    "\n",
    "weather_schema = StructType([\n",
    "    StructField(\"datetime\", DateType(), True),\n",
    "    StructField(\"temp\", FloatType(), True),\n",
    "    StructField(\"feelslike\", FloatType(), True),\n",
    "    StructField(\"humidity\", FloatType(), True),\n",
    "    StructField(\"precip\", FloatType(), True),\n",
    "    StructField(\"precipprob\", IntegerType(), True),\n",
    "    StructField(\"snowdepth\", FloatType(), True),\n",
    "    StructField(\"windspeed\", FloatType(), True),\n",
    "    StructField(\"cloudcover\", FloatType(), True),\n",
    "    StructField(\"visibility\", FloatType(), True),\n",
    "    StructField(\"solarradiation\", FloatType(), True),\n",
    "    StructField(\"solarenergy\", FloatType(), True),\n",
    "])\n",
    "\n",
    "weather_dataframe = spark.createDataFrame([], schema=weather_schema)\n",
    "\n",
    "for file_name in files:\n",
    "    file_path = f\"{folder_path}{file_name}\"\n",
    "    file_data = spark.read.format(\"csv\").option(\"header\", \"true\").load(file_path)\n",
    "    \n",
    "    # Cast correct data type for new data frame\n",
    "    for field in weather_schema.fields:\n",
    "        column_name = field.name\n",
    "        file_data = file_data.withColumn(column_name, file_data[column_name].cast(field.dataType))\n",
    "\n",
    "    current_file_df = (file_data\n",
    "        .withColumn(\"datetime\", to_date(\"datetime\"))\n",
    "        .select(*weather_schema.fieldNames())\n",
    "    )\n",
    "\n",
    "    weather_dataframe = weather_dataframe.union(current_file_df)\n",
    "    print(f\"Aggregated data till ${file_name}\")\n",
    "\n",
    "numeric_column_names = [column.name for column in weather_schema if isinstance(column.dataType, (IntegerType, FloatType))]\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=numeric_column_names,\n",
    "    outputCols=numeric_column_names,\n",
    "    strategy=\"mean\"\n",
    ")\n",
    "\n",
    "imputer_model = imputer.fit(weather_dataframe)\n",
    "weather_dataframe = imputer_model.transform(weather_dataframe)\n",
    "weather_dataframe = weather_dataframe.orderBy(\"datetime\")\n",
    "\n",
    "weather_dataframe.show()\n",
    "weather_dataframe.write.format('delta').mode('overwrite').save(\"dbfs:/dataframes/weather_dataframe\")\n",
    "print(\"Weather dataframe created and saved in DBFS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b2e3900-efa4-4959-9f8f-dbd460ee532a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Step 5:** Combine `citibike_dataframe` and `weather_dataframe` and save as `combined_dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08bfbea8-23fd-4e67-a105-167ca94e3715",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+----+----------+----+---------+--------+------+----------+---------+---------+----------+----------+--------------+-----------+\n|  datetime|day_of_week|month|year|trip_count|temp|feelslike|humidity|precip|precipprob|snowdepth|windspeed|cloudcover|visibility|solarradiation|solarenergy|\n+----------+-----------+-----+----+----------+----+---------+--------+------+----------+---------+---------+----------+----------+--------------+-----------+\n|2022-01-01|          7|    1|2022|     20895|11.6|     11.6|    91.6|18.463|       100|      0.0|     13.1|     100.0|       8.7|          14.7|        1.3|\n|2022-01-02|          1|    1|2022|     44234|10.2|      9.4|    83.8| 2.318|       100|      0.0|     22.9|      91.5|      11.8|          26.0|        2.1|\n|2022-01-03|          2|    1|2022|     34126|-1.0|     -6.2|    49.9|   0.0|         0|      0.0|     26.1|      63.4|      16.0|          12.5|        1.1|\n|2022-01-04|          3|    1|2022|     37879|-2.6|     -6.5|    49.1|   0.0|         0|      0.0|     19.9|      10.1|      16.0|         105.8|        9.1|\n|2022-01-05|          4|    1|2022|     35080| 4.2|      2.0|    77.0| 5.745|       100|      0.0|     20.5|      67.2|      13.5|          23.9|        2.1|\n|2022-01-06|          5|    1|2022|     46004| 3.2|      0.3|    50.2|   0.0|         0|      2.5|     21.3|      31.2|      16.0|          65.7|        5.8|\n|2022-01-07|          6|    1|2022|     17838|-0.9|     -5.9|    65.9| 9.314|       100|     10.4|     24.0|      72.4|      10.1|          78.0|        6.7|\n|2022-01-08|          7|    1|2022|     25129|-3.3|     -7.4|    44.1|   0.0|         0|      8.2|     24.0|       7.9|      16.0|         112.9|        9.7|\n|2022-01-09|          1|    1|2022|     22088| 2.2|     -1.7|    66.8| 2.765|       100|      5.4|     22.3|      77.8|      14.8|          29.8|        2.5|\n|2022-01-10|          2|    1|2022|     35717|-0.7|     -5.6|    47.0|   0.0|         0|      1.7|     33.6|      41.7|      15.9|         103.4|        8.9|\n|2022-01-11|          3|    1|2022|     27704|-7.3|    -12.9|    40.8|   0.0|         0|      0.1|     35.3|      10.7|      15.5|         115.1|       10.1|\n|2022-01-12|          4|    1|2022|     41636|-0.2|     -3.8|    46.2|   0.0|         0|      0.0|     22.3|      16.5|      16.0|          94.1|        8.3|\n|2022-01-13|          5|    1|2022|     51798| 4.4|      3.2|    59.3|   0.0|         0|      0.0|     11.6|      39.4|      15.7|          82.5|        7.1|\n|2022-01-14|          6|    1|2022|     46837| 3.1|     -0.7|    66.2|   0.0|         0|      0.0|     29.6|      34.6|      15.9|          89.0|        7.8|\n|2022-01-15|          7|    1|2022|     23717|-8.7|    -14.9|    45.3|   0.0|         0|      0.0|     22.4|      14.2|      16.0|          98.6|        8.7|\n|2022-01-16|          1|    1|2022|     21588|-6.3|    -11.9|    64.9| 5.546|       100|      0.1|     29.3|      57.0|      13.6|          64.7|        5.6|\n|2022-01-17|          2|    1|2022|     29887| 3.6|     -0.7|    75.8|26.429|       100|      0.4|     34.9|      98.7|      12.4|          17.9|        1.6|\n|2022-01-18|          3|    1|2022|     44045| 0.6|     -4.2|    46.6|   0.0|         0|      0.0|     28.8|      52.4|      16.0|          99.9|        8.7|\n|2022-01-19|          4|    1|2022|     55371| 4.6|      2.1|    47.9|   0.0|         0|      0.0|     22.3|      29.0|      16.0|          74.8|        6.4|\n|2022-01-20|          5|    1|2022|     34901| 2.1|     -1.5|    61.3| 6.116|       100|      0.3|     22.3|      69.8|      12.6|          37.3|        3.1|\n+----------+-----------+-----+----+----------+----+---------+--------+------+----------+---------+---------+----------+----------+--------------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "weather_dataframe = spark.read.format(\"delta\").load(\"dbfs:/dataframes/weather_dataframe\")\n",
    "citibike_dataframe = spark.read.format(\"delta\").load(\"dbfs:/dataframes/citibike_dataframe\")\n",
    "\n",
    "combined_dataframe = citibike_dataframe.join(weather_dataframe, \"datetime\", \"outer\")\n",
    "combined_dataframe.write.format('delta').mode('overwrite').save(\"dbfs:/dataframes/combined_dataframe\")\n",
    "combined_dataframe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0aa4c5c-15a0-4a4d-b6ee-9f7c8ed5cdfb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Step 6:** Filter training and testing data and save as separate dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60ca0eb9-d55c-4622-b9d6-038e02fa158c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+----+----------+----+---------+--------+------+----------+---------+---------+----------+----------+--------------+-----------+\n|  datetime|day_of_week|month|year|trip_count|temp|feelslike|humidity|precip|precipprob|snowdepth|windspeed|cloudcover|visibility|solarradiation|solarenergy|\n+----------+-----------+-----+----+----------+----+---------+--------+------+----------+---------+---------+----------+----------+--------------+-----------+\n|2022-01-01|          7|    1|2022|     20895|11.6|     11.6|    91.6|18.463|       100|      0.0|     13.1|     100.0|       8.7|          14.7|        1.3|\n|2022-01-02|          1|    1|2022|     44234|10.2|      9.4|    83.8| 2.318|       100|      0.0|     22.9|      91.5|      11.8|          26.0|        2.1|\n|2022-01-03|          2|    1|2022|     34126|-1.0|     -6.2|    49.9|   0.0|         0|      0.0|     26.1|      63.4|      16.0|          12.5|        1.1|\n|2022-01-04|          3|    1|2022|     37879|-2.6|     -6.5|    49.1|   0.0|         0|      0.0|     19.9|      10.1|      16.0|         105.8|        9.1|\n|2022-01-05|          4|    1|2022|     35080| 4.2|      2.0|    77.0| 5.745|       100|      0.0|     20.5|      67.2|      13.5|          23.9|        2.1|\n|2022-01-06|          5|    1|2022|     46004| 3.2|      0.3|    50.2|   0.0|         0|      2.5|     21.3|      31.2|      16.0|          65.7|        5.8|\n|2022-01-07|          6|    1|2022|     17838|-0.9|     -5.9|    65.9| 9.314|       100|     10.4|     24.0|      72.4|      10.1|          78.0|        6.7|\n|2022-01-08|          7|    1|2022|     25129|-3.3|     -7.4|    44.1|   0.0|         0|      8.2|     24.0|       7.9|      16.0|         112.9|        9.7|\n|2022-01-09|          1|    1|2022|     22088| 2.2|     -1.7|    66.8| 2.765|       100|      5.4|     22.3|      77.8|      14.8|          29.8|        2.5|\n|2022-01-10|          2|    1|2022|     35717|-0.7|     -5.6|    47.0|   0.0|         0|      1.7|     33.6|      41.7|      15.9|         103.4|        8.9|\n|2022-01-11|          3|    1|2022|     27704|-7.3|    -12.9|    40.8|   0.0|         0|      0.1|     35.3|      10.7|      15.5|         115.1|       10.1|\n|2022-01-12|          4|    1|2022|     41636|-0.2|     -3.8|    46.2|   0.0|         0|      0.0|     22.3|      16.5|      16.0|          94.1|        8.3|\n|2022-01-13|          5|    1|2022|     51798| 4.4|      3.2|    59.3|   0.0|         0|      0.0|     11.6|      39.4|      15.7|          82.5|        7.1|\n|2022-01-14|          6|    1|2022|     46837| 3.1|     -0.7|    66.2|   0.0|         0|      0.0|     29.6|      34.6|      15.9|          89.0|        7.8|\n|2022-01-15|          7|    1|2022|     23717|-8.7|    -14.9|    45.3|   0.0|         0|      0.0|     22.4|      14.2|      16.0|          98.6|        8.7|\n|2022-01-16|          1|    1|2022|     21588|-6.3|    -11.9|    64.9| 5.546|       100|      0.1|     29.3|      57.0|      13.6|          64.7|        5.6|\n|2022-01-17|          2|    1|2022|     29887| 3.6|     -0.7|    75.8|26.429|       100|      0.4|     34.9|      98.7|      12.4|          17.9|        1.6|\n|2022-01-18|          3|    1|2022|     44045| 0.6|     -4.2|    46.6|   0.0|         0|      0.0|     28.8|      52.4|      16.0|          99.9|        8.7|\n|2022-01-19|          4|    1|2022|     55371| 4.6|      2.1|    47.9|   0.0|         0|      0.0|     22.3|      29.0|      16.0|          74.8|        6.4|\n|2022-01-20|          5|    1|2022|     34901| 2.1|     -1.5|    61.3| 6.116|       100|      0.3|     22.3|      69.8|      12.6|          37.3|        3.1|\n+----------+-----------+-----+----+----------+----+---------+--------+------+----------+---------+---------+----------+----------+--------------+-----------+\nonly showing top 20 rows\n\n+----------+-----------+-----+----+----------+----+---------+--------+------+----------+---------+---------+----------+----------+--------------+-----------+\n|  datetime|day_of_week|month|year|trip_count|temp|feelslike|humidity|precip|precipprob|snowdepth|windspeed|cloudcover|visibility|solarradiation|solarenergy|\n+----------+-----------+-----+----+----------+----+---------+--------+------+----------+---------+---------+----------+----------+--------------+-----------+\n|2023-01-01|          1|    1|2023|     52561|11.1|     11.0|    64.9| 0.365|       100|      0.0|     20.0|      33.8|      15.4|          96.4|        8.4|\n|2023-01-02|          2|    1|2023|     60369|11.3|     11.0|    62.3|  0.44|       100|      0.0|     12.1|      55.7|      15.5|          43.8|        3.6|\n|2023-01-03|          3|    1|2023|     53591|10.6|     10.3|    87.9| 9.585|       100|      0.0|     12.5|      90.4|       8.7|          16.2|        1.5|\n|2023-01-04|          4|    1|2023|     76968|14.4|     14.2|    79.7| 0.459|       100|      0.0|     15.2|      67.6|      13.3|          59.1|        5.1|\n|2023-01-05|          5|    1|2023|     74016| 8.5|      7.0|    90.7|  0.46|       100|      0.0|     15.2|     100.0|       9.6|          26.9|        2.3|\n|2023-01-06|          6|    1|2023|     67023| 6.8|      5.0|    78.5|  6.76|       100|      0.0|     19.1|      93.0|      12.4|          31.3|        2.8|\n|2023-01-07|          7|    1|2023|     61270| 4.8|      1.9|    60.9|   0.0|         0|      0.0|     16.3|      43.2|      16.0|          50.8|        4.4|\n|2023-01-08|          1|    1|2023|     51149| 3.0|      0.7|    53.0|   0.0|         0|      0.0|     24.1|      18.7|      16.0|          86.4|        7.4|\n|2023-01-09|          2|    1|2023|     63617| 4.4|      2.3|    61.5| 0.129|       100|      0.0|     18.6|      49.1|      15.3|          97.0|        8.2|\n|2023-01-10|          3|    1|2023|     68693| 4.3|      2.3|    54.7|   0.0|         0|      0.0|     13.4|      87.8|      15.8|          23.5|        1.9|\n|2023-01-11|          4|    1|2023|     69327| 3.0|      0.0|    54.7|   0.0|         0|      0.0|     18.1|      83.7|      16.0|          47.2|        4.0|\n|2023-01-12|          5|    1|2023|     53216| 7.0|      5.5|    81.6| 4.855|       100|      0.0|     21.5|     100.0|      13.6|          16.2|        1.5|\n|2023-01-13|          6|    1|2023|     67539| 9.4|      8.0|    75.8| 4.105|       100|      0.0|     23.5|      88.3|      14.8|          26.6|        2.1|\n|2023-01-14|          7|    1|2023|     44968| 1.2|     -3.7|    62.9|   0.0|         0|      0.0|     29.5|      99.8|      14.8|          44.1|        3.8|\n|2023-01-15|          1|    1|2023|     42381| 1.2|     -3.8|    50.9|   0.0|         0|      0.0|     35.3|      42.4|      16.0|         111.7|        9.7|\n|2023-01-16|          2|    1|2023|     51554| 2.6|     -1.3|    35.2|   0.0|         0|      0.0|     27.7|      30.9|      16.0|         116.6|       10.1|\n|2023-01-17|          3|    1|2023|     66948| 5.6|      4.3|    33.3|   0.0|         0|      0.0|     15.0|      64.4|      16.0|          49.8|        4.3|\n|2023-01-18|          4|    1|2023|     78025| 8.8|      7.0|    58.5|  1.22|       100|      0.0|     30.6|      58.8|      15.8|          73.5|        6.4|\n|2023-01-19|          5|    1|2023|     33472| 5.5|      3.6|    78.5|20.571|       100|      0.0|     15.0|      74.3|      10.6|          10.0|        0.6|\n|2023-01-20|          6|    1|2023|     69848| 6.8|      4.6|    69.1|  0.08|       100|      0.0|     26.6|      88.2|      15.7|          60.0|        5.1|\n+----------+-----------+-----+----+----------+----+---------+--------+------+----------+---------+---------+----------+----------+--------------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "combined_dataframe = spark.read.format(\"delta\").load(\"dbfs:/dataframes/combined_dataframe\")\n",
    "\n",
    "training_dataframe = combined_dataframe.filter(combined_dataframe.year == 2022)\n",
    "testing_dataframe = combined_dataframe.filter(combined_dataframe.year == 2023)\n",
    "\n",
    "training_dataframe = training_dataframe.orderBy(\"datetime\")\n",
    "testing_dataframe = testing_dataframe.orderBy(\"datetime\")\n",
    "\n",
    "training_dataframe.show()\n",
    "testing_dataframe.show()\n",
    "\n",
    "training_dataframe.write.format('delta').mode('overwrite').save(\"dbfs:/dataframes/training_dataframe\")\n",
    "testing_dataframe.write.format('delta').mode('overwrite').save(\"dbfs:/dataframes/testing_dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "122f1731-f2ee-4352-ae6a-c581fc7e62a9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2. Build ML Pipeline using Training Data\n",
    "Used RandomForestRegressor with 4 trees for regression modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f37f3841-87cd-40eb-a55d-e2a45fb72ff4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML Pipeline built using training data\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Features for the model\n",
    "feature_columns = [\"day_of_week\", \"temp\", \"feelslike\", \"precip\", \"precipprob\", \"snowdepth\", \"windspeed\", \"cloudcover\", \"visibility\", \"solarradiation\", \"solarenergy\"]\n",
    "\n",
    "# Create a pipeline\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"unscaled_features\")\n",
    "scaler = StandardScaler(inputCol=\"unscaled_features\", outputCol=\"features\", withMean=True, withStd=True)\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"trip_count\", numTrees=4)\n",
    "pipeline = Pipeline(stages=[assembler, scaler, rf])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "training_dataframe = spark.read.format(\"delta\").load(\"dbfs:/dataframes/training_dataframe\")\n",
    "model = pipeline.fit(training_dataframe)\n",
    "print(\"ML Pipeline built using training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "339bc069-d8f8-4c5e-8095-e63680985cd2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. Evaluate ML Pipeline using Testing Data\n",
    "\n",
    "Last generated performance metrics:\n",
    "```\n",
    "Evaluation Results:\n",
    "  - R-squared value: 0.8050408605160813\n",
    "  - Mean Absolute Error (MAE): 10625.695028780337\n",
    "  - Performance Category:\n",
    "      MAE < 12000 (Better)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69485ce7-6b59-4cd4-bcb6-27bb178a7053",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mEvaluation Results:\u001B[0m\n  - R-squared value: 0.8050408605160813\n  - Mean Absolute Error (MAE): 10625.695028780337\n  - Performance Category:\n      \u001B[42mMAE < 12000 (Better)\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Make predictions on the testing data\n",
    "testing_dataframe = spark.read.format(\"delta\").load(\"dbfs:/dataframes/testing_dataframe\")\n",
    "predictions = model.transform(testing_dataframe)\n",
    "\n",
    "# Evaluate the performance using RegressionEvaluator\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"trip_count\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator_mae.evaluate(predictions)\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"trip_count\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "reasonable_performance = mae < 15000\n",
    "better_performance = mae < 12000\n",
    "\n",
    "print(\"\\033[1mEvaluation Results:\\033[0m\")\n",
    "print(f\"  - R-squared value: {r2}\")\n",
    "print(f\"  - Mean Absolute Error (MAE): {mae}\")\n",
    "print(\"  - Performance Category:\")\n",
    "print(\n",
    "    f\"      \\033[42m{'MAE < 12000 (Better)'}\\033[0m\" if better_performance\n",
    "    else f\"      \\033[43m{'MAE < 15000 (Reasonable)'}\\033[0m\" if reasonable_performance\n",
    "    else f\"      \\033[41m{'MAE >= 15000 (Can be better!)'}\\033[0m\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3727427279658687,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "assignment_2_student",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
